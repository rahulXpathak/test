{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e4415c2",
   "metadata": {},
   "source": [
    "\n",
    "# Statistics Part 2 - Theoretical Answers\n",
    "\n",
    "## 1. What is hypothesis testing in statistics?\n",
    "Hypothesis testing is a statistical method used to determine whether there is enough evidence in a sample of data to infer that a certain condition is true for the entire population. It helps in making decisions based on data rather than assumptions.\n",
    "\n",
    "## 2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
    "- **Null Hypothesis (Hâ‚€)**: It represents the default assumption that there is no effect, no difference, or no relationship in the population.\n",
    "- **Alternative Hypothesis (Hâ‚ or Ha)**: It contradicts the null hypothesis and represents the effect, difference, or relationship that we want to test.\n",
    "\n",
    "Example:  \n",
    "Hâ‚€: The new drug has no effect on blood pressure.  \n",
    "Hâ‚: The new drug significantly affects blood pressure.\n",
    "\n",
    "## 3. What is the significance level in hypothesis testing, and why is it important?\n",
    "The significance level (denoted as **Î±**) is the probability of rejecting the null hypothesis when it is actually true. Common values are 0.05 (5%) or 0.01 (1%). A lower Î± reduces the risk of false positives but may increase false negatives.\n",
    "\n",
    "## 4. What does a P-value represent in hypothesis testing?\n",
    "The **P-value** measures the probability of obtaining a test result at least as extreme as the observed data, assuming the null hypothesis is true.\n",
    "\n",
    "- **Small P-value (â‰¤ Î±)**: Strong evidence against Hâ‚€, leading to its rejection.\n",
    "- **Large P-value (> Î±)**: Weak evidence against Hâ‚€, so we fail to reject it.\n",
    "\n",
    "## 5. How do you interpret the P-value in hypothesis testing?\n",
    "- **P-value â‰¤ 0.05**: Strong evidence against the null hypothesis â†’ Reject Hâ‚€.\n",
    "- **P-value > 0.05**: Insufficient evidence to reject Hâ‚€ â†’ Fail to reject Hâ‚€.\n",
    "\n",
    "Example: If a test results in **P = 0.03**, we reject Hâ‚€ at a 5% significance level.\n",
    "\n",
    "## 6. What are Type 1 and Type 2 errors in hypothesis testing?\n",
    "- **Type 1 Error (False Positive)**: Rejecting Hâ‚€ when it is actually true. (False alarm)\n",
    "- **Type 2 Error (False Negative)**: Failing to reject Hâ‚€ when it is actually false. (Missed detection)\n",
    "\n",
    "Example:  \n",
    "- Type 1: A healthy patient is diagnosed with a disease.\n",
    "- Type 2: A sick patient is not diagnosed with the disease.\n",
    "\n",
    "## 7. What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
    "- **One-tailed test**: Tests if a parameter is **either greater or less** than a certain value (but not both).\n",
    "- **Two-tailed test**: Tests if a parameter is **different** (either greater or smaller) from a certain value.\n",
    "\n",
    "Example:  \n",
    "- One-tailed: \"New medicine reduces blood pressure\" (only one direction).\n",
    "- Two-tailed: \"New medicine affects blood pressure\" (either increase or decrease).\n",
    "\n",
    "## 8. What is the Z-test, and when is it used in hypothesis testing?\n",
    "A **Z-test** is used to compare a sample mean to a known population mean when:\n",
    "1. The population variance is known.\n",
    "2. The sample size is large (n â‰¥ 30).\n",
    "\n",
    "Example: Comparing the average test scores of students to a national average.\n",
    "\n",
    "## 9. How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
    "The **Z-score** formula:  \n",
    "\\[Z = \\frac{(X - \\mu)}{\\sigma / \\sqrt{n}}\n",
    "\\]\n",
    "\n",
    "Where:  \n",
    "- \\( X \\) = sample mean  \n",
    "- \\( \\mu \\) = population mean  \n",
    "- \\( \\sigma \\) = population standard deviation  \n",
    "- \\( n \\) = sample size  \n",
    "\n",
    "The Z-score represents how many standard deviations the sample mean is from the population mean.\n",
    "\n",
    "## 10. What is the T-distribution, and when should it be used instead of the normal distribution?\n",
    "The **T-distribution** is similar to the normal distribution but is used when:\n",
    "1. The sample size is **small (n < 30)**.\n",
    "2. The population standard deviation is **unknown**.\n",
    "\n",
    "It is more spread out than the normal distribution but approaches normal as sample size increases.\n",
    "\n",
    "## 11. What is the difference between a Z-test and a T-test?\n",
    "| Z-test | T-test |\n",
    "|--------|--------|\n",
    "| Used when population variance is **known**. | Used when population variance is **unknown**. |\n",
    "| Sample size is **large (n â‰¥ 30)**. | Sample size is **small (n < 30)**. |\n",
    "| Uses normal distribution. | Uses T-distribution. |\n",
    "\n",
    "## 12. What is a confidence interval, and how is it used to interpret statistical results?\n",
    "A **confidence interval (CI)** is a range of values that is likely to contain the true population parameter. It is calculated as:\n",
    "\\[CI = \text{sample mean} \\pm (\text{critical value} \times \text{standard error})\n",
    "\\]\n",
    "\n",
    "For example, a 95% CI of [45, 55] means we are 95% confident that the population mean is between 45 and 55.\n",
    "\n",
    "## 13. What is an ANOVA test, and what are its assumptions?\n",
    "**ANOVA (Analysis of Variance)** tests whether there are significant differences among multiple group means.\n",
    "\n",
    "**Assumptions of ANOVA:**  \n",
    "1. **Normality** â€“ Data should be normally distributed.  \n",
    "2. **Independence** â€“ Observations should be independent.  \n",
    "3. **Equal Variance (Homogeneity of variance)** â€“ Variances in different groups should be similar.\n",
    "\n",
    "## 14. What is the F-test, and how does it relate to hypothesis testing?\n",
    "The **F-test** is used to compare two variances and check if they are significantly different.\n",
    "\n",
    "- **Hâ‚€**: The variances are equal.\n",
    "- **Hâ‚**: The variances are different.\n",
    "\n",
    "Formula:\n",
    "\\[F = \\frac{\text{Variance of group 1}}{\text{Variance of group 2}}\n",
    "\\]\n",
    "If \\( F \\) is significantly high or low, we reject the null hypothesis.\n",
    "\n",
    "## 14. What is the margin of error, and how does it affect the confidence interval?\n",
    "The margin of error (ME) quantifies uncertainty in a confidence interval. A larger sample size reduces ME, making the interval narrower and more precise.\n",
    "\n",
    "## 15. How is Bayes' Theorem used in statistics, and what is its significance?\n",
    "Bayes' Theorem helps update probabilities based on new evidence. Formula:\n",
    "\n",
    "ð‘ƒ\n",
    "(\n",
    "ð´\n",
    "âˆ£\n",
    "ðµ\n",
    ")\n",
    "=\n",
    "ð‘ƒ\n",
    "(\n",
    "ðµ\n",
    "âˆ£\n",
    "ð´\n",
    ")\n",
    "â‹…\n",
    "ð‘ƒ\n",
    "(\n",
    "ð´\n",
    ")\n",
    "ð‘ƒ\n",
    "(\n",
    "ðµ\n",
    ")\n",
    "P(Aâˆ£B)= \n",
    "P(B)\n",
    "P(Bâˆ£A)â‹…P(A)\n",
    "â€‹\n",
    " \n",
    "It is used in spam filtering, medical diagnosis, and machine learning.\n",
    "\n",
    "## 16. What is the Chi-square distribution, and when is it used?\n",
    "The Chi-square distribution is used to test relationships between categorical variables. It is used in:\n",
    "\n",
    "Chi-square goodness of fit test (checks if data fits expected distribution).\n",
    "Chi-square test for independence (tests if two categorical variables are related).\n",
    "## 17. What is an ANOVA test, and what are its assumptions?\n",
    "ANOVA (Analysis of Variance) compares means across multiple groups. Assumptions:\n",
    "\n",
    "The data is normally distributed.\n",
    "The groups have equal variance.\n",
    "The samples are independent.\n",
    "## 18. What are the different types of ANOVA tests?\n",
    "One-way ANOVA â€“ Compares means across one independent variable.\n",
    "Two-way ANOVA â€“ Compares means across two independent variables.\n",
    "Repeated Measures ANOVA â€“ Compares means when the same subjects are tested multiple times.\n",
    "## 19. What is the F-test, and how does it relate to hypothesis testing?\n",
    "The F-test compares variances between two or more groups to test if they are significantly different. It is commonly used in ANOVA tests.\n",
    "\n",
    "## 23. What is an ANOVA test, and what are its assumptions?\n",
    "ANOVA (Analysis of Variance) tests whether there are significant differences among multiple group means.\n",
    "\n",
    "Assumptions of ANOVA:\n",
    "\n",
    "Normality â€“ Data should be normally distributed.\n",
    "Independence â€“ Observations should be independent.\n",
    "Equal Variance (Homogeneity of variance) â€“ Variances in different groups should be similar.\n",
    "\n",
    "## 24. What are the different types of ANOVA tests?\n",
    "One-way ANOVA â€“ Compares means of multiple groups for one independent variable.\n",
    "Two-way ANOVA â€“ Compares means of groups across two independent variables.\n",
    "Repeated Measures ANOVA â€“ Compares means when the same subjects are measured multiple times.\n",
    "\n",
    "## 25. What is the F-test, and how does it relate to hypothesis testing?\n",
    "The F-test is used to compare two variances and check if they are significantly different.\n",
    "\n",
    "Hâ‚€: The variances are equal.\n",
    "Hâ‚: The variances are different.\n",
    "Formula:\n",
    "\n",
    "ð¹\n",
    "=\n",
    "VarianceÂ ofÂ groupÂ 1\n",
    "VarianceÂ ofÂ groupÂ 2\n",
    "F= \n",
    "VarianceÂ ofÂ groupÂ 2\n",
    "VarianceÂ ofÂ groupÂ 1\n",
    "â€‹\n",
    " \n",
    "If \n",
    "ð¹\n",
    "F is significantly high or low, we reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cfefc8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics Part 2 - Practical Solutions\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, t, chisquare, chi2_contingency\n",
    "import pandas as pd\n",
    "\n",
    "# Q1: Perform a Z-test\n",
    "\n",
    "def z_test(sample, population_mean, population_std):\n",
    "    sample_mean = np.mean(sample)\n",
    "    n = len(sample)\n",
    "    z_score = (sample_mean - population_mean) / (population_std / np.sqrt(n))\n",
    "    p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
    "    return z_score, p_value\n",
    "\n",
    "# Q2: Hypothesis testing with random data\n",
    "\n",
    "def simulate_hypothesis_test():\n",
    "    sample_data = np.random.normal(loc=50, scale=5, size=30)\n",
    "    t_stat, p_value = stats.ttest_1samp(sample_data, 50)\n",
    "    return t_stat, p_value\n",
    "\n",
    "# Q3: One-sample Z-test\n",
    "\n",
    "def one_sample_z_test(sample, population_mean, population_std):\n",
    "    return z_test(sample, population_mean, population_std)\n",
    "\n",
    "# Q4: Two-tailed Z-test with visualization\n",
    "\n",
    "def two_tailed_z_test(sample, population_mean, population_std):\n",
    "    z_score, p_value = z_test(sample, population_mean, population_std)\n",
    "    x = np.linspace(-4, 4, 1000)\n",
    "    y = norm.pdf(x, 0, 1)\n",
    "    plt.plot(x, y)\n",
    "    plt.axvline(x=-1.96, color='r', linestyle='--')\n",
    "    plt.axvline(x=1.96, color='r', linestyle='--')\n",
    "    plt.show()\n",
    "    return z_score, p_value\n",
    "\n",
    "# Q5: Visualizing Type 1 & Type 2 errors\n",
    "\n",
    "def visualize_type1_type2():\n",
    "    x = np.linspace(-4, 4, 1000)\n",
    "    y1, y2 = norm.pdf(x, 0, 1), norm.pdf(x, 1, 1)\n",
    "    plt.plot(x, y1, label=\"H0\")\n",
    "    plt.plot(x, y2, label=\"H1\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Q6: Independent T-test\n",
    "\n",
    "def independent_t_test():\n",
    "    group1, group2 = np.random.normal(50, 5, 30), np.random.normal(52, 5, 30)\n",
    "    return stats.ttest_ind(group1, group2)\n",
    "\n",
    "# Q7: Paired T-test\n",
    "\n",
    "def paired_t_test():\n",
    "    before, after = np.random.normal(50, 5, 30), np.random.normal(52, 5, 30)\n",
    "    return stats.ttest_rel(before, after)\n",
    "\n",
    "# Q8: Compare Z-test and T-test\n",
    "\n",
    "def compare_z_t_test():\n",
    "    sample = np.random.normal(50, 5, 30)\n",
    "    z_result = z_test(sample, 50, 5)\n",
    "    t_stat, p_value = stats.ttest_1samp(sample, 50)\n",
    "    return z_result, (t_stat, p_value)\n",
    "\n",
    "# Q9: Confidence interval\n",
    "\n",
    "def confidence_interval(sample, confidence=0.95):\n",
    "    sample_mean, sample_std, n = np.mean(sample), np.std(sample, ddof=1), len(sample)\n",
    "    t_score = t.ppf((1 + confidence) / 2, df=n-1)\n",
    "    moe = t_score * (sample_std / np.sqrt(n))\n",
    "    return (sample_mean - moe, sample_mean + moe)\n",
    "\n",
    "# Q10: Margin of error\n",
    "\n",
    "def margin_of_error(sample, confidence=0.95):\n",
    "    return confidence_interval(sample, confidence)\n",
    "\n",
    "# Q11: Bayesian inference\n",
    "\n",
    "def bayes_theorem(prior_A, prob_B_given_A, prob_B_given_not_A):\n",
    "    prob_not_A = 1 - prior_A\n",
    "    prob_B = (prob_B_given_A * prior_A) + (prob_B_given_not_A * prob_not_A)\n",
    "    return (prob_B_given_A * prior_A) / prob_B\n",
    "\n",
    "# Q12: Chi-square test for independence\n",
    "\n",
    "def chi_square_test():\n",
    "    observed = np.array([[20, 30], [10, 40]])\n",
    "    return chi2_contingency(observed)\n",
    "\n",
    "# Q13: Expected frequencies for Chi-square test\n",
    "\n",
    "def expected_frequencies():\n",
    "    observed = np.array([[25, 35], [15, 25]])\n",
    "    _, _, _, expected = chi2_contingency(observed)\n",
    "    return expected\n",
    "\n",
    "# Q14: Goodness-of-fit test\n",
    "\n",
    "def goodness_of_fit():\n",
    "    observed, expected = np.array([50, 30, 20]), np.array([40, 40, 20])\n",
    "    return chisquare(observed, expected)\n",
    "\n",
    "# Running all functions and saving results to a DataFrame\n",
    "if __name__ == \"__main__\":\n",
    "    sample_data = np.random.normal(50, 5, 30)\n",
    "    results = {\n",
    "        \"Z-Test\": z_test(sample_data, 50, 5),\n",
    "        \"Hypothesis Test\": simulate_hypothesis_test(),\n",
    "        \"One-Sample Z-Test\": one_sample_z_test(sample_data, 50, 5),\n",
    "        \"Two-Tailed Z-Test\": two_tailed_z_test(sample_data, 50, 5),\n",
    "        \"Independent T-Test\": independent_t_test(),\n",
    "        \"Paired T-Test\": paired_t_test(),\n",
    "        \"Compare Z vs T-Test\": compare_z_t_test(),\n",
    "        \"Confidence Interval\": confidence_interval(sample_data),\n",
    "        \"Margin of Error\": margin_of_error(sample_data),\n",
    "        \"Bayes' Theorem\": bayes_theorem(0.01, 0.95, 0.05),\n",
    "        \"Chi-Square Test\": chi_square_test(),\n",
    "        \"Expected Frequencies\": expected_frequencies(),\n",
    "        \"Goodness-of-Fit Test\": goodness_of_fit()\n",
    "    }\n",
    "    df_results = pd.DataFrame(results, index=[\"Statistic\", \"P-Value\"])\n",
    "    print(df_results)\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "# Q15: Perform an F-test to compare variances of two samples\n",
    "def f_test(sample1, sample2):\n",
    "    f_stat = np.var(sample1, ddof=1) / np.var(sample2, ddof=1)\n",
    "    df1, df2 = len(sample1) - 1, len(sample2) - 1\n",
    "    p_value = 1 - stats.f.cdf(f_stat, df1, df2)\n",
    "    return f_stat, p_value\n",
    "\n",
    "# Q16: Perform an ANOVA test to compare means of multiple groups\n",
    "def anova_test(*groups):\n",
    "    return f_oneway(*groups)\n",
    "\n",
    "# Q17: Perform a one-way ANOVA test and visualize results\n",
    "def one_way_anova_visualized(*groups):\n",
    "    stat, p_value = f_oneway(*groups)\n",
    "    plt.boxplot(groups, labels=[f'Group {i+1}' for i in range(len(groups))])\n",
    "    plt.title(\"One-Way ANOVA Comparison\")\n",
    "    plt.show()\n",
    "    return stat, p_value\n",
    "\n",
    "# Q18: Check ANOVA assumptions (normality, independence, equal variance)\n",
    "def check_anova_assumptions(*groups):\n",
    "    normality = [stats.shapiro(group)[1] for group in groups]\n",
    "    variances = stats.levene(*groups)[1]\n",
    "    return normality, variances\n",
    "\n",
    "# Q19: Perform a two-way ANOVA test\n",
    "def two_way_anova(df, factor1, factor2, response):\n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.formula.api import ols\n",
    "    model = ols(f'{response} ~ C({factor1}) + C({factor2}) + C({factor1}):C({factor2})', data=df).fit()\n",
    "    return sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Q20: Visualize F-distribution\n",
    "def visualize_f_distribution():\n",
    "    x = np.linspace(0, 5, 1000)\n",
    "    y = stats.f.pdf(x, dfn=10, dfd=20)\n",
    "    plt.plot(x, y, label=\"F-Distribution\")\n",
    "    plt.fill_between(x, y, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Q21: Perform a hypothesis test for population variance\n",
    "def chi_square_variance_test(sample, hypothesized_variance):\n",
    "    n = len(sample)\n",
    "    sample_var = np.var(sample, ddof=1)\n",
    "    chi2_stat = (n - 1) * sample_var / hypothesized_variance\n",
    "    p_value = 1 - stats.chi2.cdf(chi2_stat, df=n-1)\n",
    "    return chi2_stat, p_value\n",
    "\n",
    "# Q22: Perform a Z-test for comparing proportions\n",
    "def z_test_proportions(p1, p2, n1, n2):\n",
    "    p_pool = (p1 * n1 + p2 * n2) / (n1 + n2)\n",
    "    se = np.sqrt(p_pool * (1 - p_pool) * (1/n1 + 1/n2))\n",
    "    z_score = (p1 - p2) / se\n",
    "    p_value = 2 * (1 - norm.cdf(abs(z_score)))\n",
    "    return z_score, p_value\n",
    "\n",
    "# Q23: Implement an F-test for comparing variances\n",
    "def f_test_variances(sample1, sample2):\n",
    "    return f_test(sample1, sample2)\n",
    "\n",
    "# Q24: Perform a Chi-square test for goodness of fit\n",
    "def chi_square_goodness_of_fit(observed, expected):\n",
    "    return chisquare(observed, expected)\n",
    "\n",
    "# Q25: Simulate random data from a normal distribution and perform hypothesis testing\n",
    "def simulate_and_test():\n",
    "    sample_data = np.random.normal(50, 5, 30)\n",
    "    return stats.ttest_1samp(sample_data, 50)\n",
    "\n",
    "# Q26: Perform a two-way ANOVA test with visualization\n",
    "def two_way_anova_visual(df, factor1, factor2, response):\n",
    "    result = two_way_anova(df, factor1, factor2, response)\n",
    "    result.plot(kind='bar')\n",
    "    plt.title(\"Two-Way ANOVA Results\")\n",
    "    plt.show()\n",
    "    return result\n",
    "\n",
    "# Q27: Perform a one-way ANOVA test and visualize results with boxplots\n",
    "def one_way_anova_boxplot(*groups):\n",
    "    stat, p_value = f_oneway(*groups)\n",
    "    plt.boxplot(groups, labels=[f'Group {i+1}' for i in range(len(groups))])\n",
    "    plt.title(\"One-Way ANOVA with Boxplots\")\n",
    "    plt.show()\n",
    "    return stat, p_value\n",
    "\n",
    "# Running all functions if executed as script\n",
    "if __name__ == \"__main__\":\n",
    "    sample1 = np.random.normal(50, 5, 30)\n",
    "    sample2 = np.random.normal(52, 5, 30)\n",
    "    results = {\n",
    "        \"F-Test\": f_test(sample1, sample2),\n",
    "        \"One-Way ANOVA\": one_way_anova_visualized(sample1, sample2),\n",
    "        \"ANOVA Assumptions\": check_anova_assumptions(sample1, sample2),\n",
    "        \"Chi-Square Variance Test\": chi_square_variance_test(sample1, 25),\n",
    "        \"Z-Test Proportions\": z_test_proportions(0.5, 0.4, 100, 100),\n",
    "        \"Chi-Square Goodness of Fit\": chi_square_goodness_of_fit([50, 30, 20], [40, 40, 20]),\n",
    "        \"Simulated Hypothesis Test\": simulate_and_test()\n",
    "    }\n",
    "    df_results = pd.DataFrame(results, index=[\"Statistic\", \"P-Value\"])\n",
    "    print(df_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae67b575",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
